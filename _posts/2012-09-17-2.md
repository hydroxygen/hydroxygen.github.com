---
layout: post
title: 入门：世纪佳缘用户推荐
category: notes
tags: 世纪佳缘数据 入门文章
---

##**简介**
这是本人第一篇正式的推荐技术文章，选择了2011年举办的第一届数据挖掘邀请赛的"世纪佳缘会员推荐"赛题
的数据，对原问题做了一些简化处理。在严程的[推荐系统入门实践：世纪佳缘会员推荐（完整版）][原文]
研究的基础上，做出了一些自己的改进，并得出一些结论。虽然微不足道，但是毕竟是自己做出的成果，暂且写下，待日后来挖。

##**题目简介**
该题目来自于世纪佳缘网站上用户对被推荐给他的用户的行为（无行为，点击，发信）数据，要求通过分析行为数据
以及用户的资料，预测测试集合上用户的行为。详见[原文]。

##**评价指标**
评价指标采用NDCG，其定义如下：

![2-1](/assets/images/2-1.gif)

其中DCG定义为：

![2-2](/assets/images/2-2.gif)

![2-3](/assets/images/2-3.gif)指代得分而Ideal DCG是指评分足够理想时能够获得的DCG最大值。

##**数据处理**
数据由train.txt和profile.txt组成，分别表示用户对被推荐给其的其他用户的行为以及用户自身的特征。
这里的train.txt还包括了多次不同推荐时的数据，即包括时间戳。为了简单起见，本文对数据做了一下处理，即
如果一个用户对被推荐给他的用户在不同时间做出了不同的行为，那么选择取得分最高的一次。（msg > click > rec）

在评价时，为了与原作者的结果进行对比，故采用了与原作者相同的评价指标。1.将数据均分成5份，以其中4份作为
训练数据，另一份作为测试数据，评价结果好坏。2.仍以4份作为训练数据，但将整个数据集作为测试数据。

评价方法设计的并不好，首先评价标准1没有采用交叉验证的办法，结果可能并不是那么准。评价标准2更是存在过拟合
的问题，不过可以通过与评价标准1相对比发现过拟合的问题。这点在介绍具体算法时会指出来。

其他一些问题的描述详见[原文]。下面进入正题。


##**推荐算法**

###基于投票加权的大众欢迎度

以下是原作者的算法及说明：

>  Train.txt中第二列为被推荐用户，这些用户大多为老用户。根据这些用户被推荐的历史记录，按照一定的模型，
> 	可以得到每个老用户受大众欢迎的程度。该模型定义如下：
> 	Popularity = msg_weight * msg_times + click_weight * click_times + rec_weight * rec_times  
> 	上式中各参数含义非常明确，分别表示3种行为（msg|click|rec）的权重与次数的加权和。很容易理解，某个老
> 	用户被rec，click，甚至msg的次数越多，某种程度上就说明该用户更加受到公众的喜爱，三种行
> 	为的权重顺序为msg click rec，依次取值100，10，1。  
> 	基于上述模型和train_train.txt，就可以得到多数老用户的大众欢迎程度。由于采用随机分配原则，
> 	train_train.txt中的大部分老用户，同样会出现在train_test.txt中。有了这些老用户的大众欢迎度排名，针对
> 	train_test.txt中的大部分被推荐用户，就可以根据相应的大众欢迎度进行排名，如果某个用户没有出现在
> 	train_train.txt中，则采用设置popularity为0的简单处理办法。最终可以得到针对train_test.txt中userA的推
> 	荐用户顺序列表文件myranks_train_test.txt。然后根据上述评分模型评测方法，可以计算得到本模型针对
> 	train_test.txt的NDCG@10和NDCG@20分值：
> 	(0.5760898362334391, 0.6026498518875004)   
> 	同理基于该模型可得到针对train.txt中userA的推荐用户顺序列表文件myranks_train.txt。然后根据上述评分模
> 	型评测方法，可以计算得到本模型针对train.txt的NDCG@10和NDCG@20分值：
> 	(0.15788352658143304, 0.19271909879690152)

这里我对这种算法的思路表示理解，但是对于作者对msg，click，rec行为定义的权值产生怀疑。感觉作者的权值设定
也太随便了吧。因此，我修改权值的表示，做了如下实验：

**实验1-1：**修改msg，click，rec的权值为2，1.5，1。（这是原作者在后面基于加权的推荐时采用的最优权值）  
结果：在2个测试集合上的NDCG得分变为：  
 (0.088988316452093708, 0.12002833452742749)和(0.53752679142387072, 0.56432531832360799)  
效果变差了许多。思考了下认为是msg，click的权值变得和rec差不多时，大众流行度就差不多变成统计一个人被推荐的次数了，这个值的含义显然失去了大众流行度本身的意义。

**实验1-2：**修改msg，click，rec的权值为10000，100，1。  
结果：在2个测试集合上的NDCG得分变为：  
(0.19640530223777819, 0.23671812951966029)和(0.60496949320244786, 0.63250990387853445)  
比原作者的结果有了进一步的提升。这让我有进一步扩大行为间权值的冲动。

**实验1-3：**修改msg，click，rec的权值为100000000，10000，1。  
结果：在2个测试集合上的NDCG得分变为：  
(0.19832429907821861, 0.23924426862006939)和(0.60609620038865653, 0.6339280433055352)  

**实验表明：**仅基于投票的大众流行度基本可以说只与行为权重较高的msg和click相关。这让我想起《推荐系统实践》
中作者提到的“对用户没有产生过行为的物品抽样作为负样本时，尽量做到正负样本数均衡”。这里的rec就相当于
“对用户没有产生过行为的物品”，由于rec样本比msg和click都多了200倍的样子，所以如果权值相差不大，msg和click就很容易
淹没在rec这个“负样本”的海洋中。所以对msg，click的权值应该与rec拉开足够的差距。


###基于投票加权平均的大众欢迎度

以下是原作者的算法及说明：

> 基于投票加权的大众欢迎度模型，仅考虑了每个老用户被推荐的总次数以及相应行为权重的加权和信息，但忽略了一
> 	个重要信息。例如，某2个老用户A和B的加权和相同，均为100，但用户A被推荐了20次，而用户B仅被推荐了10次，即
> 	用户B在更少的推荐次数内得到了同样的访问量。因此，我们可以认为用户B相对来讲拥有更高的大众欢迎度。
> 	基于这种思路，我们改进了上述模型，得到新的投票加权平均模型：  
> 	Popularity = ( msg_weight * msg_times + click_weight * click_times + rec_weight * rec_times) / (msg_times + click_times + rec_times)   	
> 	类似地，这里三种行为权重msg click rec，依次取值100，10，1。  
> 	按照类似的处理步骤，基于该模型，针对train_test.txt中userA的推荐用户顺序列表文件myranks_train_test.txt。	
> 	然后根据上述评分模型评测方法，可以计算得到本模型针对train_test.txt的NDCG@10和NDCG@20分值：
> 	(0.6251315909409053, 0.6531515387910409)	
> 	同理基于该模型可得到针对train.txt中userA的推荐用户顺序列表文件myranks_train.txt。然后根据上述评分模型
> 	评测方法，可以计算得到本模型针对train.txt的NDCG@10和NDCG@20分值：
> 	(0.22950347745869737, 0.2728895216170754)   	
> 	在此基础上，当我们尝试针对三种行为使用不同的权重时，结果会有微妙的变化。最终，我们经验性地发现，当三种
> 	行为权重msg click rec，依次取值2，1.5，1时，能得到相对最好的结果，分别为：
> 	(0.6345833528026847, 0.6619046966636642)
> 	(0.2571459631326702, 0.30000037338792146)
> 	这里的0.25XXXX相比随机模型的0.08XXXX已经有了很大提升，足以说明本模型已极大地提升了推荐效果。

这里，我感觉基于每个人投票次数的加权无可厚非。但是可能存在的一个问题是：如果一个用户只被推荐了1次，正好收到
msg，那他的popular是否应该冠绝全场呢？显然是不合理的。于是我尝试用下列方式对popular的计算进行了修改。

**实验2-1：**假设用avgnum表示每个人平均被推荐的次数，用avgscore表示平均每个人的得分。那么，对被推荐次数不足avgnum
的用户，其得分的一部分用avgscore表示。计算公式为：  
popular = score * (num/avgnum) + avgscore * (1-num/avgnum) （num < avgnum）  
其中num表示这个人被推荐的次数，score表示原始的popular得分。
结果：在2个测试集合上的NDCG得分变为：
(0.25057863228113131, 0.29368524767943743)和(0.6357299289111259, 0.66289174267527273)  
在测试集合上的得分比原作者取得的得分更高一些。说明这样做还是有些道理的。于是我又对模型进行了进一步修改。

**实验2-2：**实验2-1的一个主要问题在于对被推荐次数过少的优质用户不公平。比如如果一个人被推荐了10次，全部收到msg
，那说明至少这个人是比较靠谱的。而依据2-1的popular计算公式：当每个人平均被推荐次数为1000时，这个人的得分就
与平均得分大致相当了，这显然不合理。于是我对2-1的公式修改如下：  
popular = score * 0.7 + avgscore * 0.3  （num < avgnum）   
这时每个人的平均得分同时来自于个性化的得分与平均分。在2个测试集合上的得分为：  
(0.25882867244574581, 0.30157532607298598)和(0.63577963265923099, 0.66323324161722763)  


**实验2-3：**实验2-2在原有基础上进一步提升了效果。但是它并没有考虑被推荐次数这个很重要的参数，于是，我试图对
2-2的计算公式做进一步修改，使其与被推荐次数相关，并最终得到如下计算公式：  
rate = num/avgnum * 0.5 + 0.5  
rate与被推荐次数占平均被推荐次数的比例相关，同时为了避免2-1的不足，弱化这部分比例，使其更与个性化得分相关。
然后计算popular = score * rate + avgscore * (1 - rate)  （num < avgnum）  
这个方案结合了2-1和2-2的优点，既重点考虑了个性化得分，又使权值与被推荐次数相关。结果如下：  
(0.25971002348079641, 0.30211778202771977)和(0.63609376965192999, 0.66351148975087948)  
效果确实又更上了一层楼。

这一节的几个实验均是在我不知道威尔逊区间的情况下做的。其实这几个方案跟威尔逊区间一样同时考虑了用户自身的
个性化得分以及被推荐的次数，不过威尔逊区间通过置信度把两者更好的结合到了一块。不过这几个方案在原有单纯加权
的基础上做了一些简单的计算，就能让效果提升不少，还是有其可取之处的。

###基于Learning to Rank

原文标题是基于SVM-Rank，但SVM-Rank本来就是一种Learning to Rank的方法。原文采用的方法描述如下：
>   虽然上述基于大众欢迎度的评分模型已经极大地提升了推荐系统的效果，但至今我们没有使用过用户的任何Profile信息，而这些信息很有可能成为我们忽视的重要信息。

>   从附件“数据库表.xlsx”中我们可以方便地提取一些重要特征字段，这些字段很可能会直接影响到用户userA是否会在查看某个userB的资料（click）后进而给他发送站内信息（msg）。这里我们提取了如下4个主要特征字段：

>   Last_login：用户是否活跃（active），如果最近3个月都未登陆过，新用户可能不太会想跟TA联系；   
>   Status：用户是否处于征友状态（demand），如果已经在跟他人联系，将不易被推荐；  
>   Login_count：登陆次数（count），如果某个用户登陆次数太少，新用户可能会觉得跟他联系希望不大；  
>   Avatar：是否有头像（picture），虽然某些新用户不要求对方有头像，但如果有头像，肯定会起到加分的作用。  
>   再结合上述大众欢迎度（popularity），这里共计有5个特征，构成特征向量：  
>   Feature_vector = （popularity，active，demand，count，picture）  
>   要想充分利用这些特征向量信息来训练一个有效的评分模型，最直接的想法就是利用一种用于排序问题的SVM方法：SVM-Rank。  
> 	SVM-Rank这一方法是经典的Learning to rank问题中的一种重要方法，传统的SVM方法是一种用于解决分类问题的机器学习方法，这里SVM-Rank通过将排序问题转化为分类问题，来间接实现某种信息的排序。  
> 	要使用SVM-Rank，可以通过其官网进行了解学习。该程序具备特定的输入与输出格式，以及某些重要的参数设置。其输入格式遵从Learning to rank问题领域的标准测试用数据集LETOR的格式要求，如下所示：

>   ![2-4](/assets/images/2-4.gif)

>   其中，第二列qid:n为某次查询的编号，这里共包含3次查询，每次返回4个结果。第一列为每次查询结果中对应4个结果的相对排序。后面依次给出了5个特征序号及对应的特征值。#后为注释信息，会被程序自动忽略。  
> 	回到我们的问题，我们已经提取了5个特征，基于train.txt、profile_m.txt和profile_f.txt我们可以轻松获取每个老用户的特征向量。那么要利用SVM-Rank，就必须将这些特征向量按照给定的格式生成SVM-Rank训练和预测所需的文件。  
> 	以5倍交叉验证的模型测评方式为例：  
> 	首先，我们基于train_train.txt，利用上述投票加权平均的大众欢迎度模型计算多数用户的欢迎度排名user_popularity.txt。  
> 	其次，基于user_popularity.txt，profile_m.txt和profile_f.txt计算大多数老用户的特征向量文件user_feature_vector.txt以及后面将被SVM-rank使用的预测数据集user_feature_vector_for_predict.txt。  
> 	然后，按照给定的格式生成SVM-Rank训练模型所需的输入文件user_svm_train_file.txt，并使用SVM-Rank训练模型参数。需要注意的是，训练集中需要包含为每个用户userA推荐的用户列表的真实排序。为某个用户userA推荐一个包含N个用户的列表，就相当于一次查询，返回N个结果。作为训练集，这N个结果的排序必须是已知的。遗憾的是，竞赛中未能提供这样一种数据来反应所有老用户的实际排序，为此，我们只能采用上述大众欢迎度user_popularity.txt的结果来为这N个用户排序，以便构成训练集。  
> 	最后，利用SVM-Rank和user_feature_vector_for_predict.txt预测大多数用户的分值，对所有用户的分值进行排序，就可以针对train_test.txt或train.txt得到所有被推荐用户的排序，进而得到模型的测评分值。  

>   基于该评分模型，针对train_test.txt中userA的推荐用户顺序列表文件myranks_train_test.txt。然后根据上述评分模型评测方法，可以计算得到本模型针对train_test.txt的NDCG@10和NDCG@20分值：  
>   (0.6344312058678667, 0.661812638898174)  
>   同理基于该模型可得到针对train.txt中userA的推荐用户顺序列表文件myranks_train.txt。然后根据上述评分模型评测方法，可以计算得到本模型针对train.txt的NDCG@10和NDCG@20分值：  
>   (0.2570729864787669, 0.300026754320666)  
> 	与上述模型结果进行比较，发现将大众欢迎度与用户profile信息进行结合，采用Learning to rank的方法并不能对结果有明显提升。

原作者在使用Learning to rank时犯了一个很大的错误，即使用用户的受欢迎度代替用户排序。这是很不科学的做法，因为用户受欢迎度是我们计算出来的数值，非原始数据，与实际情况误差较大。而Learning to rank对数据的误差非常敏感，少量误差极有可能带来很大的错误。而且在预测用户受欢迎度时，本身就用到了用户受欢迎度的数值。这不就是用自己拟合自己吗？

**实验3-1：**我根据实际情况，使用用户的具体行为作为拟合对象，用SVM-RANK拟合原作者提供的feature，结果如下：  
(0.2557907977815374, 0.2986885313752366)和(0.63399663866877376, 0.6616909727300927)  
这是用SVM-RANK的真实拟合情况，比原作者效果更差。

**实验3-2：**SVM-RANK拟合的得分用用户行为 + 大众流行度表示。  
分析实验3-1失败的原因，我猜测会不会是因为根据用户行为的分别度太差导致的，因为用户区分度只有3个档次，从而导致SVM-RANK拟合不够。  
因此想到的一个解决方法是通过增加得分档次来加强区分度，这点可以通过在用户行为得分的基础上增加归一化后的流行度来实现。这样做的结果如下：  
(0.25732916658692251, 0.30012161559170819)和(0.63460731846870222, 0.66195467588128509)  
略好于原来的结果。

但是，效果仍然不如预期，难道Learning to rank真的在这个数据集合上没有用吗？

**实验3-3：**原作者只选用了4个featrue，加上大众流行度也不过5个，而profile文件提供了34个用户featrue。为了充分利用这些feature，我重新从featrue列表中筛选出了17个featrue做训练，仍然采用采用用户行为 + 大众流行度表示用户得分。用SVM-RANK跑的时候老是出现死循环（跑一整天都跑不出结果）。于是改用了另一种Learning to rank的算法[lambdarank]，效果如下：  
(0.25894664853865162, 0.30265384013013719)和(0.63535975308437487, 0.66299759865671715)  

**实验3-4：**将大众流行度的计算公式改为大众流行度的计算公式改为实验2-3的结果。用lambdamart训练出来的结果为：  
(0.26057295876312281, 0.30378136735367062)和(0.63710699217463407, 0.66465226848868708)  
整体效果首次超过0.26！

**实验3-5：**之前实验3-3的17个feature选择中，有一部分类似用户a-用户b的特征，比如身高差距，年龄差距，学历差距等等。当初设计时没考虑到用户男女有别，一律采用的是被推荐用户-推荐用户的形式。后来觉得这样不妥，于是把这一类特征改成男-女的形式，训练结果为：  
(0.26190484025296684, 0.30545850577515993)和(0.63738876067467176, 0.66505134663281962)

Learning to rank确实是一个比较好用的方法，也比较适合于推荐系统。因为推荐系统做的事情可以归结为预测所有物品在用户那里的喜好度排序。于是我们可以利用历史数据，通过训练用户对已有物品的排序情况，用于预测用户对未知物品的排序。不过这样做需要选择良好的用户和物品feature。物品feature尤为重要！是一个基于内容推荐的方法，对于物品特征提取困难的场景就不是很适用了。

###基于威尔逊区间的大众欢迎度

看过原文后，才发现威尔逊区间原来是这么好用的一个好评度计算方法。原文对威尔逊空间的应用描述如下：

>   上述基于投票加权平均的排序方法，是比较常规的依据经验设计的排序模型，而本小节将要介绍的基于威尔逊区间的排序算法是来源于具备强大理论基础的统计学知识。  
>   最初接触到基于威尔逊区间排序是来自于阮一峰老师的博客，其博客上先后连载了6篇不同的排序算法。其中，Delicious和Hacker News、Reddit、Stack Overflow及牛顿冷却定律等算法主要永固解决一定时间内的热门话题排序问题，排序受时间影响很大；而威尔逊区间及贝叶斯平均更为灵活，可以解决与时间无关的排序问题。  
>   本小节关注基于威尔逊区间的排序问题。大概原理根据阮一峰老师的介绍，再经过自己的整理介绍如下。  
>   首先将用户对某一话题或评论的投票问题进行如下假设：     	
>   每个用户的投票都是独立事件 	
>   用户只有两个选择，要么投赞成票，要么投反对票
>   如果投票总人数为n，其中赞成票为k，那么赞成票的比例p就等于k/n
>   那么针对某个评论的大量用户投票事件就可以转化为一个统计学上的二项分布问题。在样本足够多，即投票数量n越大时，概率p可信度越大，如果p越高，就说明该话题越受欢迎，这没有问题。但问题出在对于某些话题投票数n相对太少，这时的概率p的可信度会大大降低，即使p很高，也不敢妄下结论说该话题非常受欢迎。  
>     根据以上假设，我们知道p是"二项分布"中某个事件（投赞成票）的发生概率，因此我们可以计算出p的置信区间。所谓"置信区间"，是指以某个概率而言，p会落在的那个区间。比如，某个话题的赞成率是80%，但是这个值不一定可信。根据统计学，我们只能说，有95%的把握可以断定，赞成率在75%到85%之间，即置信区间是\[75%, 85%\]。这样我们就可以得到一个根据置信概率确定排名的算法框架，分为以下三步：

>  计算每个话题的"赞成率"（即赞成票的比例）   
>  计算每个"赞成率"的置信区间（以95%的概率）   
>  第三步，根据置信区间的下限值，进行排名。这个值越大，排名就越高

>   置信区间的实质，就是进行可信度的修正，弥补样本量过小的影响。如果样本多，就说明比较可信，不需要很大的修正，所以置信区间会比较窄，下限值会比较大；如果样本少，就说明不一定可信，必须进行较大的修正，所以置信区间会比较宽，下限值会比较小。

>   现在话题的排名问题转化为计算二项分布的置信区间问题，统计学上广泛使用的“正态区间”方法只适用于样本足够多的情形。为了解决小样本的置信区间计算准确性问题，1927年，美国数学家 Edwin Bidwell Wilson提出了一个修正公式，被称为"威尔逊区间"，很好的解决了这个问题。基于威尔逊区间的置信区间计算公式如下：  
>   ![2-5](/assets/images/2-5.gif)  
> 	上述公式中，![2-6](/assets/images/2-6.gif) 表示某一话题的“赞成票比例“，n表示样本大小，![2-7](/assets/images/2-7.gif)表示对应某个置信水平的z统计量，这是一个常量，可以通过查表得到。一般情况下，在85%和95%的置信水平下z统计值分别为1.0和1.6。

>   威尔逊置信区间的下限值为：

>   ![2-8](/assets/images/2-8.gif)  

>   可以看到，当n的值足够大时，这个下限值会趋向![2-6](/assets/images/2-6.gif)。如果n非常小（投票人很少），这个下限值会大大小于![2-6](/assets/images/2-6.gif)。实际上，起到了降低"赞成票比例"的作用，使得该项目的得分变小、排名下降。
>   这就是目前Reddit评论使用的主要排名算法。

>   现在回到我们这里所要面对的问题，即如何应用威尔逊区间法给出世纪佳缘会员的排名。威尔逊区间法将实际排序问题抽象为二项分布的统计问题，这里将世纪佳缘每个老会员看作一个话题，在过去有很多其他会员对他们进行了rec，click甚至msg三种操作，可以看作3种投票，所以无法直接应用威尔逊区间法进行排序。

>   但是，根据经验，某个老会员被其它会员进行click或msg，都说明其它会员对这个老会员有一定好感，2种情形都可认为是“投赞成票”，而如果老会员仅仅是被系统推荐rec，说明其它会员不感兴趣，则可以认为是“投反对票”，由此，可以将问题转化为一个“二项分布”的统计问题。

>   这里，我们给定三种事件rec，click和msg以不同的权重（分别为1，1.5，2），则对于某个老会员，赞成票数为：  
>   Ups = msg_weight * msg_times + click_weight * click_times  
>   反对票数为：  
>   Downs = rec_weight * rec_times
>   那么投票的赞成率p = ups / (ups + downs)  
>   于是就可以使用威尔逊区间法给出排序。  
>   具体在排序算法中的核心函数，即计算针对每个老会员的投票赞成率的置信区间时，参考率Reddit评论排序的开源代码。

>   基于该评分模型，针对train_test.txt中userA的推荐用户顺序列表文件myranks_train_test.txt。然后根据上述评分模型评测方法，可以计算得到本模型针对train_test.txt的NDCG@10和NDCG@20分值：  
>   (0.6373419863408559, 0.6640676330359446)  
>   同理基于该模型可得到针对train.txt中userA的推荐用户顺序列表文件myranks_train.txt。然后根据上述评分模型评测方法，可以计算得到本模型针对train.txt的NDCG@10和NDCG@20分值：  
>   (0.26356889450029836, 0.30645765290261523)
> 	与基于投票加权平均的排序模型结果进行比较，发现该模型仍有进一步提高。

**实验4-1：**
原作者在实验中是取85%置信度的结果。如果选择95%置信度，结果为：  
(0.26347265178124157, 0.30619560249863909)和(0.63729639123086967, 0.66416053606042635)  

**实验4-2：**
使用lambdamart对威尔逊区间的大众流行度进行训练时，结果为：  
(0.26350750939201445, 0.30757013673931716)和(0.54445022999620774, 0.57174276885372577)  
效果反而变差，尤其是测试集合上的效果，这点我很不理解。分析了下可能的原因，我觉得很可能是与现有的特征选取有关，训练出现了过拟合的现象。

**实验4-3：**
原作者对click_weight和msg_weight的取值分别是1.5和2。这点我表示不太理解，因为它对正负反馈做了不同的加权，而且同样是正反馈，两种行为的取值也不同。因此我调整了click_weight和msg_weight，当两者均为1时，发现结果为：  
(0.26450862204500453, 0.30770244341113162)和(0.63753548097159929, 0.66429604674599296)  
继续调整，发现当click_weight和msg_weight两者权值很接近时，效果就比较不错，如：
click_weight=1.6，msg_weight=1.4时，结果为：  
0.264945076057183981 0.308316307046969273 0.637528013492845269 0.664079845054746487  
而click_weight=1.0，msg_weight=0.9时，结果如下：  
0.265002233563040701 0.308033083828844423 0.637571610180429960 0.664225710016262294  
说明用威尔逊区间下限做预测时，如果对积极的行为和消极的行为都取同样的权值，目测效果较好。当然也可能只对本数据集合有用。


##**总结**
第一次写技术博客，感觉太过流程化。过于注重实验数据，而对思考过程的描述和经验教训的总结比较单薄。这点会在接下来的博文中改进。



[原文]: http://www.cnblogs.com/supersteven/archive/2012/09/01/2666565.html
[lambdarank]: http://people.cs.umass.edu/~vdang/ranklib.html
{% include references.md %}
